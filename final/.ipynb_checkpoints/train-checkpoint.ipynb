{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████▎                                 | 10499/20000 [9:29:32<10:48:18,  4.09s/it]D:\\ProgramData\\Anaconda3\\envs\\ykio\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      " 72%|███████████████████████████████████████████████████▏                   | 14407/20000 [12:56:06<5:27:32,  3.51s/it]"
     ]
    }
   ],
   "source": [
    "import Junction2x2\n",
    "import Agent\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "train = False\n",
    "epoch = 20000 if train else 1\n",
    "agent = [0,0,0,0]\n",
    "# agent[0] = Agent.DQNAgent(state_size=28, action_size=8, train=train)\n",
    "# agent[1] = Agent.DQNAgent(state_size=28, action_size=8, train=train)\n",
    "# agent[2] = Agent.DQNAgent(state_size=28, action_size=8, train=train)\n",
    "# agent[3] = Agent.DQNAgent(state_size=28, action_size=8, train=train)\n",
    "agent[0] = Agent.DQNAgent(state_size=28, action_size=8, train=False, state_dict=torch.load(\"test/0.pth\"))\n",
    "agent[1] = Agent.DQNAgent(state_size=28, action_size=8, train=False, state_dict=torch.load(\"test/1.pth\"))\n",
    "agent[2] = Agent.DQNAgent(state_size=28, action_size=8, train=False, state_dict=torch.load(\"test/2.pth\"))\n",
    "agent[3] = Agent.DQNAgent(state_size=28, action_size=8, train=False, state_dict=torch.load(\"test/3.pth\"))\n",
    "reward_info, step_info, longest_wait = [[] for i in range(4)], [], [[] for i in range(4)]\n",
    "avg_rewards, avg_steps, avg_long_wait = [0, 0, 0, 0], 0, [0, 0, 0, 0]\n",
    "\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    env = Junction2x2.Junction2x2()\n",
    "    r, l = [0, 0, 0, 0], [0, 0, 0, 0]\n",
    "    for step in range(300):\n",
    "        states = list()\n",
    "        actions = list()\n",
    "        for j in range(4):\n",
    "            state = env.get_adjusted_state(j)\n",
    "            states.append(state)\n",
    "            action = agent[j].get_action(state)\n",
    "            actions.append(action)\n",
    "\n",
    "        j1,j2,j3,j4 = env.step(actions)\n",
    "        J = [j1,j2,j3,j4]\n",
    "        if train:\n",
    "            for j in range(4):\n",
    "                next_state, reward, done = J[j]\n",
    "                agent[j].append_sample(states[j], actions[j], reward, next_state, done)\n",
    "                agent[j].train_model()\n",
    "                r[j] += reward\n",
    "                l[j] = max(l[j], env.J[j].get_oldest())\n",
    "\n",
    "        done_list = [j1[2], j2[2], j3[2], j4[2]]\n",
    "        if any(done_list):\n",
    "            break\n",
    "        if not train:\n",
    "            print(env.render())\n",
    "            sleep(0.1)\n",
    "\n",
    "    if not train:\n",
    "        for j in range(4):\n",
    "            env.J[j].save_graph(f\"performance/performance{j}.png\")\n",
    "    \n",
    "    if train:\n",
    "        if i % 500 == 499:\n",
    "            for j in range(4):\n",
    "                torch.save(agent[j].model.state_dict(), f\"weight/save{j}_{i + 1}.pth\")\n",
    "                \n",
    "        for j in range(4):\n",
    "            avg_rewards[j] = r[j] if avg_rewards[j] == 0 else avg_rewards[j] * 0.9 + r[j] * 0.1\n",
    "            avg_long_wait[j] = l[j] if avg_long_wait[j] == 0 else avg_long_wait[j] * 0.9 + l[j] * 0.1\n",
    "        avg_steps = (step + 1) if avg_steps == 0 else avg_steps * 0.9 + (step + 1) * 0.1\n",
    "\n",
    "        for j in range(4):\n",
    "            reward_info[j].append(avg_rewards[j])\n",
    "            longest_wait[j].append(avg_long_wait[j])\n",
    "        step_info.append(avg_steps)\n",
    "\n",
    "        if i % 500 == 499:\n",
    "            fig = plt.figure()\n",
    "            for j in range(4):\n",
    "                plt.subplot(2, 2, j + 1)\n",
    "                plt.scatter(range(len(reward_info[j])), reward_info[j], s=1)\n",
    "\n",
    "                plt.savefig(f\"graph/reward{i + 1}.png\")\n",
    "            plt.clf()\n",
    "\n",
    "            for j in range(4):\n",
    "                plt.subplot(2, 2, j + 1)\n",
    "                plt.scatter(range(len(longest_wait[j])), longest_wait[j], s=1)\n",
    "\n",
    "                plt.savefig(f\"graph/longest_wait{i + 1}.png\")\n",
    "            plt.clf()\n",
    "\n",
    "            plt.scatter(range(len(step_info)), step_info, s=1)\n",
    "            plt.savefig(f\"graph/step{i + 1}.png\")\n",
    "            plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
